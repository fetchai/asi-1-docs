import {CodeGroup, DocsCode} from "../../../../components/code";

# Create an Agent to be part of the ASI knowledge base

## Introduction

[ASI-1](https://asi1.ai/) is an LLM created by Fetch.ai, unlike other LLMs ASI-1 connects to [Agents](https://uagents.fetch.ai/docs/) which act as domain experts allowing ASI-1 to answer specialist questions, make reservations and become an access point to an _organic_ multi-Agent ecosystem.

This guide is the preliminary step of getting your Agents onto ASI-1 by getting your Agent online, active and using the chat protocol to enable you to communicate with your Agent via [chat.agentverse.ai](https://chat.agentverse.ai).

## Why be part of the knowledge base

By building agents to connect to ASI-1 we extend the LLM's knowledge base, but also create new opportunities for monetization. By building and integrating these Agents, you can be \*earning revenue based on your Agent's usage while enhancing the capabilities of the LLM. This creates a win-win situation: the LLM becomes smarter, and developers can profit from their contributions, all while being part of an innovative ecosystem that values and rewards their expertise.

Alrighty, let's get started!

## Getting started

    - Head over to [ASI-1](https://asi1.ai/), and [create an API key](/docs/core/api-key).
    - Make sure you have [uAgents package installed](https://uagents.fetch.ai/docs/quickstart).
    - Sign up to [Agentverse](https://agentverse.ai) so that you can create a [mailbox](https://uagents.fetch.ai/docs/agentverse/mailbox) for your Agent.

Don't fret, we explain these topics in this guide.

## Chat protocol

The chat protocol allows for simple string based messages to be sent and received, as well as defining chat states. It's the expected communication format for ASI-1. You will import this as a dependency when you install uAgents.

It is imported like so:

    `from uagents_core.contrib.protocols.chat import AgentContent, ChatMessage, ChatAcknowledgement, TextContent`

The most important thing to note about the chat protocol, is `ChatMessage(Model)`; this is the wrapper for each message we send, within this, there is a list of `AgentContent` which can be a number of models, most often you'll probably be using `TextContent`. 

An example of this is a littler further down the page.

## The Agent

We define a [local Agent](https://uagents.fetch.ai/docs/guides/types) with the following code: 

    ```py copy filename="agent.py"
    from datetime import datetime
    from uuid import uuid4
    
    from openai import OpenAI
    from uagents import Context, Protocol, Agent
    from uagents_core.contrib.protocols.chat import (
        ChatAcknowledgement,
        ChatMessage,
        EndSessionContent,
        TextContent,
        chat_protocol_spec,
    )
    
    
    ### Example Expert Assistant
    
    ## This chat example is a barebones example of how you can create a simple chat agent
    ## and connect to agentverse. In this example we will be prompting the ASI-1 model to
    ## answer questions on a specific subject only. This acts as a simple placeholder for
    ## a more complete agentic system.
    ##
    
    # the subject that this assistant is an expert in
    subject_matter = "the moon"
    
    client = OpenAI(
        # By default, we are using the ASI-1 LLM endpoint and model
        base_url='https://api.asi1.ai/v1',
    
        # You can get an ASI-1 api key by creating an account at https://asi1.ai/dashboard/api-keys
        api_key='<YOUR_API_KEY>',
    )
    
    agent = Agent(
        name="ASI-agent",
        seed="agent_seedphrase",
        port=8001,
        mailbox=True,
        publish_agent_details=True,
    )
    
    # We create a new protocol which is compatible with the chat protocol spec. This ensures
    # compatibility between agents
    protocol = Protocol(spec=chat_protocol_spec)
    
    
    # We define the handler for the chat messages that are sent to your agent
    @protocol.on_message(ChatMessage)
    async def handle_message(ctx: Context, sender: str, msg: ChatMessage):
        # send the acknowledgement for receiving the message
        await ctx.send(
            sender,
            ChatAcknowledgement(timestamp=datetime.now(), acknowledged_msg_id=msg.msg_id),
        )
    
        # collect up all the text chunks
        text = ''
        for item in msg.content:
            if isinstance(item, TextContent):
                text += item.text
    
        # query the model based on the user question
        response = 'I am afraid something went wrong and I am unable to answer your question at the moment'
        try:
            r = client.chat.completions.create(
                model="asi1-mini",
                messages=[
                    {"role": "system", "content": f"""
            You are a helpful assistant who only answers questions about {subject_matter}. If the user asks 
            about any other topics, you should politely say that you do not know about them.
                    """},
                    {"role": "user", "content": text},
                ],
                max_tokens=2048,
            )
    
            response = str(r.choices[0].message.content)
        except:
            ctx.logger.exception('Error querying model')
    
        # send the response back to the user
        await ctx.send(sender, ChatMessage(
            timestamp=datetime.utcnow(),
            msg_id=uuid4(),
            content=[
                # we send the contents back in the chat message
                TextContent(type="text", text=response),
                # we also signal that the session is over, this also informs the user that we are not recording any of the
                # previous history of messages.
                EndSessionContent(type="end-session"),
            ]
        ))
    
    
    @protocol.on_message(ChatAcknowledgement)
    async def handle_ack(ctx: Context, sender: str, msg: ChatAcknowledgement):
        # we are not interested in the acknowledgements for this example, but they can be useful to
        # implement read receipts, for example.
        pass
    
    
    # attach the protocol to the agent
    agent.include(protocol, publish_manifest=True)
    
    if __name__ == "__main__":
        agent.run()

    ```

You can get an API Key for this example [here](/docs/core/api-key).

This example sets up a simple expert assistant Agent using the uAgents Framework and connects it to the ASI-1 Mini LLM via its API. The Agent, named `ASI-agent`, is configured to operate on `port=8001` with a [mailbox](https://uagents.fetch.ai/docs/agentverse/mailbox) support and publishes its details for discovery onto the Agentverse. It uses the standardized chat protocol provided by `uagents_core.contrib.protocols.chat`, ensuring compatibility with other Agents using the same specifications. When it receives a `ChatMessage`, it acknowledges the message, extracts the user's input, and forwards it to the ASI-1 model hosted at `https://api.asi1.ai/v1`, using a predefined system prompt that restricts the assistant's responses strictly to the topic of `"the moon"`. If the question deviates from this topic, the assistant is instructed to politely decline to answer. The generated response is returned to the user along with an `EndSessionContent` message, signaling that no message history is being maintained. 

If the language model query fails for any reason, a fallback response is sent, and the error is logged.

We can start this Agent now. You should see something like this within your terminal output:

    ```
    INFO:     [ASI-agent]: Starting agent with address: agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [ASI-agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [ASI-agent]: Mailbox access token acquired
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [ASI-agent]: Manifest published successfully: AgentChatProtocol
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Registering on almanac contract...
    INFO:     [ASI-agent]:  Mailbox access token acquired
    ```

### Enabling the mailbox

Let's click the link for the [Agent inspector](https://uagents.fetch.ai/docs/agentverse/inspector); you should see a window like the below:

![](../../../../content/images/quickstart/asi-agent_1.png)

Click **connect** and in the modal select **Mailbox**.

![](../../../../content/images/quickstart/asi-agent_2.png)

You'll then see instructions to update your Agent to use the mailbox:

![](../../../../content/images/quickstart/asi-agent_3.png)

Now our Agent can receive messages from any Agent! You can read more about the mailbox [here](https://uagents.fetch.ai/docs/agentverse/mailbox).

You should now see the updated output in your terminal:

    ```
    INFO:     [ASI-agent]: Starting agent with address: agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [ASI-agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [ASI-agent]: Mailbox access token acquired
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [ASI-agent]: Manifest published successfully: AgentChatProtocol
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Registering on almanac contract...
    INFO:     [ASI-agent]:  Mailbox access token acquired
    INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse
    INFO:     [mailbox]: Agent details updated in Agentverse
    ```

Alrighty, let's chat with our Agent!

## chat.agentverse.ai

Visit [chat.agentverse.ai](https://chat.agentverse.ai), and sign in.

Using the address of your Agent, search for it using the search bar:

![](../../../../content/images/quickstart/asi-agent_4.png)

Select your Agent:

![](../../../../content/images/quickstart/asi-agent_5.png)

Click the **Start a chat** button: 

![](../../../../content/images/quickstart/asi-agent_6.png)

Then, ask your Agent a question related to its area of expertise üëç.

![](../../../../content/images/quickstart/asi-agent_7.png)

Then you should see your Agents response in the chat window:

![](../../../../content/images/quickstart/asi-agent_8.png)

Your Agent should have a terminal output log similar to the one below:


    ```
    INFO:     [ASI-agent]: Starting agent with address: agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Agent inspector available at https://agentverse.ai/inspect/?uri=http%3A//127.0.0.1%3A8001&address=agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf
    INFO:     [ASI-agent]: Starting server on http://0.0.0.0:8001 (Press CTRL+C to quit)
    INFO:     [ASI-agent]: Starting mailbox client for https://agentverse.ai
    INFO:     [ASI-agent]: Mailbox access token acquired
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [ASI-agent]: Manifest published successfully: AgentChatProtocol
    INFO:     [uagents.registration]: Registration on Almanac API successful
    INFO:     [uagents.registration]: Registering on almanac contract...
    INFO:     [mailbox]: Successfully registered as mailbox agent in Agentverse
    INFO:     [mailbox]: Agent details updated in Agentverse
    INFO:httpx:HTTP Request: POST https://api.asi1.ai/v1/chat/completions "HTTP/1.1 200 OK"
    ```


### Client Agent

Of course, you could also create a client to your Agent and skip chat.agentverse.ai, here's an example of that too:

    ```py copy filename="client.py"
    from datetime import datetime
    from uuid import uuid4
    from uagents import Agent, Context, Protocol, Model
    from uagents_core.contrib.protocols.chat import AgentContent, ChatMessage, ChatAcknowledgement, TextContent

    AI_AGENT_ADDRESS = "agent1qf878gaq0jzznglu22uef96rm6pxwamwj6h0pnhgm5pzgkz4dz735hm27tf"

    agent = Agent(
        name="asi-agent",
        seed="hiweihvhieivhwehihiweivbw;ibv;rikbv;erv;rkkbv",
        port=8002,
        endpoint=["http://127.0.0.1:8002/submit"],
    )


    @agent.on_event("startup")
    async def send_message(ctx: Context):
        await ctx.send(AI_AGENT_ADDRESS, ChatMessage(
            timestamp=datetime.now(),
            msg_id=uuid4(),
            content=[TextContent(type="text", text="Give me facts about the moon")],
        ))


    @agent.on_message(ChatAcknowledgement)
    async def handle_ack(ctx: Context, sender: str, msg: ChatAcknowledgement):
        ctx.logger.info(f"Got an acknowledgement from {sender} for {msg.acknowledged_msg_id}")


    @agent.on_message(ChatMessage)
    async def handle_ack(ctx: Context, sender: str, msg: ChatMessage):
        ctx.logger.info(f"Received request from {sender} for {msg.content[0].text}")

    agent.run()
    ```

Let's run the client like so `python client.py`, this agent sends a message to the Agent, asking for facts about the moon, and accepts two responses, `ChatAcknowledgement` and `ChatMessage`.

## Next steps

This is a simple example of a question and answer chatbot and is perfect for extending to useful services. [chat.agentverse.ai](https://chat.agentverse.ai) is the first step in getting your Agents onto ASI-1, keep an eye on our [blog](https://fetch.ai/blog) for the future release date. Additionally, remember to check out the dedicated **ASI-1 documentation** for additional information on the topic, which is available here: [ASI-1 docs](/docs).

What can you build with a dynamic chat protol, and an LLM? 

For any additional questions, the Team is waiting for you on [Discord](https://discord.gg/fetchai) and [Telegram](https://t.me/fetch_ai) channels.

\* payments are planned to be released Q3 2025.
